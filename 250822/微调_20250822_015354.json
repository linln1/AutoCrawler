[
  {
    "id": "2508.14072",
    "url": "https://arxiv.org/abs/2508.14072",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.312125",
    "title": "Multi-Objective Bayesian Optimization with Independent Tanimoto Kernel Gaussian Processes for Diverse Pareto Front Exploration",
    "authors": "Anabel Yong",
    "subjects": "Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)",
    "abstract": "We present GP-MOBO, a novel multi-objective Bayesian Optimization algorithm that advances the state-of-the-art in molecular optimization. Our approach integrates a fast minimal package for Exact Gaussian Processes (GPs) capable of efficiently handling the full dimensionality of sparse molecular fingerprints without the need for extensive computational resources. GP-MOBO consistently outperforms traditional methods like GP-BO by fully leveraging fingerprint dimensionality, leading to the identification of higher-quality and valid SMILES. Moreover, our model achieves a broader exploration of the chemical search space, as demonstrated by its superior proximity to the Pareto front in all tested scenarios. Empirical results from the DockSTRING dataset reveal that GP-MOBO yields higher geometric mean values across 20 Bayesian optimization iterations, underscoring its effectiveness and efficiency in addressing complex multi-objective optimization challenges with minimal computational overhead.",
    "comments": "Masters of Science thesis",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2508.14235",
    "url": "https://arxiv.org/abs/2508.14235",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.334214",
    "title": "SLAM-based Safe Indoor Exploration Strategy",
    "authors": "Omar Mostafa, Nikolaos Evangeliou, Anthony Tzes",
    "subjects": "Robotics (cs.RO)",
    "abstract": "This paper suggests a 2D exploration strategy for a planar space cluttered with obstacles. Rather than using point robots capable of adjusting their position and altitude instantly, this research is tailored to classical agents with circular footprints that cannot control instantly their pose. Inhere, a self-balanced dual-wheeled differential drive system is used to explore the place. The system is equipped with linear accelerometers and angular gyroscopes, a 3D-LiDAR, and a forward-facing RGB-D camera. The system performs RTAB-SLAM using the IMU and the LiDAR, while the camera is used for loop closures. The mobile agent explores the planar space using a safe skeleton approach that places the agent as far as possible from the static obstacles. During the exploration strategy, the heading is towards any offered openings of the space. This space exploration strategy has as its highest priority the agent's safety in avoiding the obstacles followed by the exploration of undetected space. Experimental studies with a ROS-enabled mobile agent are presented indicating the path planning strategy while exploring the space.",
    "comments": "5 pages, 8 figures. Published in the 2025 11th International Conference on Automation, Robotics, and Applications (ICARA)",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2508.14289",
    "url": "https://arxiv.org/abs/2508.14289",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.341577",
    "title": "\"They Aren't Built For Me\": An Exploratory Study of Strategies for Measurement of Graphical Primitives in Tactile Graphics",
    "authors": "Areen Khalaila, Lane Harrison, Nam Wook Kim, Dylan Cashman",
    "subjects": "Human-Computer Interaction (cs.HC)",
    "abstract": "Advancements in accessibility technologies such as low-cost swell form printers or refreshable tactile displays promise to allow blind or low-vision (BLV) people to analyze data by transforming visual representations directly to tactile representations. However, it is possible that design guidelines derived from experiments on the visual perception system may not be suited for the tactile perception system. We investigate the potential mismatch between familiar visual encodings and tactile perception in an exploratory study into the strategies employed by BLV people to measure common graphical primitives converted to tactile representations. First, we replicate the Cleveland and McGill study on graphical perception using swell form printing with eleven BLV subjects. Then, we present results from a group interview in which we describe the strategies used by our subjects to read four common chart types. While our results suggest that familiar encodings based on visual perception studies can be useful in tactile graphics, our subjects also expressed a desire to use encodings designed explicitly for BLV people. Based on this study, we identify gaps between the perceptual expectations of common charts and the perceptual tools available in tactile perception. Then, we present a set of guidelines for the design of tactile graphics that accounts for these gaps. Supplemental material is available at this https URL.",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2508.14718",
    "url": "https://arxiv.org/abs/2508.14718",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.400137",
    "title": "The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language Models for Recipe Generation",
    "authors": "Shubham Pundhir, Ganesh Bagler",
    "subjects": "Computation and Language (cs.CL)",
    "abstract": "We established a rigorous benchmark for text-based recipe generation, a fundamental task in natural language generation. We present a comprehensive comparative study contrasting a fine-tuned GPT-2 large (774M) model against the GPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine corpus from RecipeDB. Our key contribution is a targeted tokenization strategy that augments the vocabulary with 23 common fraction tokens and custom structural markers. This approach addresses a critical limitation of generic tokenizers by preserving essential recipe structures and precise numerical quantities, thereby enhancing domain specificity. Performance is evaluated using a comprehensive suite of seven automatic metrics spanning fluency (BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and diversity. Our experiments show that the large transformer-based approach yields a >20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the best recurrent baseline, while reducing perplexity by 69.8%. We conclude with a discussion of remaining challenges, particularly regarding factual accuracy, and outline how this foundational study paves the way for integrating real-world constraints and multi-modal inputs in advanced recipe generation research.",
    "comments": "8 pages, 4 figures. Code is available at: this https URL",
    "matched_keyword": "fine-tuning",
    "matched_category": "微调"
  },
  {
    "id": "2402.00162",
    "url": "https://arxiv.org/abs/2402.00162",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.443251",
    "title": "Behind the Myth of Exploration in Policy Gradients",
    "authors": "Adrien Bolland, Gaspard Lambrechts, Damien Ernst",
    "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "abstract": "In order to compute near-optimal policies with policy-gradient algorithms, it is common in practice to include intrinsic exploration terms in the learning objective. Although the effectiveness of these terms is usually justified by an intrinsic need to explore environments, we propose a novel analysis with the lens of numerical optimization. Two criteria are introduced on the learning objective and two others on its stochastic gradient estimates, and are afterwards used to discuss the quality of the policy after optimization. The analysis sheds light on two separate effects of exploration techniques. First, they make it possible to smooth the learning objective and to eliminate local optima while preserving the global maximum. Second, they modify the gradient estimates, increasing the probability that the stochastic parameter updates eventually provide an optimal policy. We empirically illustrate these effects with exploration strategies based on entropy bonuses, identifying limitations and suggesting directions for future work.",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2402.03055",
    "url": "https://arxiv.org/abs/2402.03055",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.444413",
    "title": "Deep Exploration with PAC-Bayes",
    "authors": "Bahareh Tasdighi, Manuel Haussmann, Nicklas Werge, Yi-Shan Wu, Melih Kandemir",
    "subjects": "Machine Learning (cs.LG)",
    "abstract": "Reinforcement learning (RL) for continuous control under delayed rewards is an under-explored problem despite its significance in real-world applications. Many complex skills are based on intermediate ones as prerequisites. For instance, a humanoid locomotor must learn how to stand before it can learn to walk. To cope with delayed reward, an agent must perform deep exploration. However, existing deep exploration methods are designed for small discrete action spaces, and their generalization to state-of-the-art continuous control remains unproven. We address the deep exploration problem for the first time from a PAC-Bayesian perspective in the context of actor-critic learning. To do this, we quantify the error of the Bellman operator through a PAC-Bayes bound, where a bootstrapped ensemble of critic networks represents the posterior distribution, and their targets serve as a data-informed function-space prior. We derive an objective function from this bound and use it to train the critic ensemble. Each critic trains an individual soft actor network, implemented as a shared trunk and critic-specific heads. The agent performs deep exploration by acting epsilon-softly on a randomly chosen actor head. Our proposed algorithm, named {\\it PAC-Bayesian Actor-Critic (PBAC)}, is the only algorithm to consistently discover delayed rewards on continuous control tasks with varying difficulty.",
    "comments": "ECAI camera-ready version; fixed acknowledgements; fixed github reference",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2405.17604",
    "url": "https://arxiv.org/abs/2405.17604",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.447455",
    "title": "LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters",
    "authors": "Klaudia Bałazy, Mohammadreza Banaei, Karl Aberer, Jacek Tabor",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abstract": "The growth of large language models underscores the need for parameter-efficient fine-tuning. Despite its popularity, LoRA encounters storage and computational challenges when deploying multiple task- or user-specific modules. To address this, we introduce LoRA-XS, a novel fine-tuning method backed by a theoretical derivation. LoRA-XS drastically reduces trainable parameters by incorporating a small, trainable weight matrix between frozen low-rank matrices derived from the Singular Value Decomposition of pre-trained weights. This design enables LoRA-XS to reduce storage requirements by over 100x in 7B models compared to LoRA. Additionally, unlike other methods, LoRA-XS imposes no lower bound on trainable parameters - it can scale from a single parameter per module to arbitrarily large values, adapting to any storage or computational constraint. Evaluations on GLUE, GSM8K, MATH, and commonsense reasoning benchmarks across different model scales reveal that LoRA-XS consistently outperforms or matches LoRA and VeRA in accuracy, offering unmatched parameter efficiency. Our ablation studies highlight the significance of singular vectors in transformer weights, establishing LoRA-XS as a powerful, storage-efficient solution for scaling and personalizing large language models.",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2412.04465",
    "url": "https://arxiv.org/abs/2412.04465",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.457773",
    "title": "UnZipLoRA: Separating Content and Style from a Single Image",
    "authors": "Chang Liu, Viraj Shah, Aiyu Cui, Svetlana Lazebnik",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
    "abstract": "This paper introduces UnZipLoRA, a method for decomposing an image into its constituent subject and style, represented as two distinct LoRAs (Low-Rank Adaptations). Unlike existing personalization techniques that focus on either subject or style in isolation, or require separate training sets for each, UnZipLoRA disentangles these elements from a single image by training both the LoRAs simultaneously. UnZipLoRA ensures that the resulting LoRAs are compatible, i.e., they can be seamlessly combined using direct addition. UnZipLoRA enables independent manipulation and recontextualization of subject and style, including generating variations of each, applying the extracted style to new subjects, and recombining them to reconstruct the original image or create novel variations. To address the challenge of subject and style entanglement, UnZipLoRA employs a novel prompt separation technique, as well as column and block separation strategies to accurately preserve the characteristics of subject and style, and ensure compatibility between the learned LoRAs. Evaluation with human studies and quantitative metrics demonstrates UnZipLoRA's effectiveness compared to other state-of-the-art methods, including DreamBooth-LoRA, Inspiration Tree, and B-LoRA.",
    "comments": "Project page: this https URL",
    "matched_keyword": "lora",
    "matched_category": "微调"
  },
  {
    "id": "2507.04487",
    "url": "https://arxiv.org/abs/2507.04487",
    "category": "cs",
    "source": "arxiv",
    "crawl_time": "2025-08-22T01:53:52.487884",
    "title": "LoSiA: Efficient High-Rank Fine-Tuning via Subnet Localization and Optimization",
    "authors": "Xujia Wang, Yunjia Qi, Bin Xu",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA, significantly reduce the number of trainable parameters by introducing low-rank decomposition matrices. However, existing methods perform extensive matrix multiplications in domain specialization tasks, resulting in computational inefficiency and sub-optimal fine-tuning performance. Hence, we propose LoSiA(Low-Resources Subnet Integration Adaptation), an innovative method that dynamically localizes and optimizes critical parameters during the training process. Specifically, it identifies a sub-network using gradient sparsity analysis and optimizes it as the trainable target. This design enables effective high-rank adaptation by updating only the sub-network parameters, reducing the additional matrix multiplication. We also present LoSiA-Pro, a faster implementation of LoSiA, which reduces the training latency by about $27\\%$ compared to LoRA. Extensive evaluations show that our method achieves minimal performance drop compared to full fine-tuning, while requiring the least training time across domain specialization and common-sense reasoning tasks. Further analysis shows that LoSiA also reduces forgetting during continued training. The source code is available at this https URL.",
    "comments": "Accepted to EMNLP 2025 (Main Conference); 18 pages, 12 figures",
    "matched_keyword": "fine-tuning",
    "matched_category": "微调"
  }
]